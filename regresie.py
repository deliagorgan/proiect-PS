import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn import linear_model
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import streamlit as st


def page_model_regresie_diabet(df_diabet):
    st.title("Model de regresie liniarÄƒ pentru predicÈ›ia diabetului")

    st.markdown("""
    Ãn aceastÄƒ secÈ›iune, vom construi un model de regresie liniarÄƒ pentru a analiza factorii care influenÈ›eazÄƒ
    hemoglobina glicatÄƒ (HbA1c) - un indicator esenÈ›ial Ã®n diagnosticarea È™i monitorizarea diabetului.
    ÃnÈ›elegerea factorilor care influenÈ›eazÄƒ nivelul HbA1c poate oferi informaÈ›ii valoroase pentru
    prevenÈ›ia È™i managementul diabetului.
    """)
    print(df_diabet)


    if not isinstance(df_diabet, pd.DataFrame):
        st.error("Nu existÄƒ date disponibile pentru analizÄƒ.")
        return df_diabet

    cols_to_drop = ['PatientID', 'DoctorInCharge'] if 'PatientID' in df_diabet.columns else []
    df_diabet_clean = df_diabet.drop(cols_to_drop, axis=1) if cols_to_drop else df_diabet.copy()

    target_variable = "HbA1c"

    if target_variable not in df_diabet_clean.columns:
        st.error(f"Variabila È›intÄƒ '{target_variable}' nu existÄƒ Ã®n setul de date.")
        return df_diabet

    st.subheader("1. Separarea datelor Ã®n caracteristici de intrare È™i È›intÄƒ")

    st.markdown(f"""
    PregÄƒtim datele pentru antrenarea modelului de regresie:
    - Variabila È›intÄƒ: **{target_variable}** (Hemoglobina glicatÄƒ - HbA1c)
    - Caracteristici de intrare: Vom selecta din setul de date variabilele relevante pentru model
    """)

    if len(df_diabet_clean) < 10:
        st.error("Nu existÄƒ suficiente date pentru a crea un model de regresie.")
        return df_diabet

    y = df_diabet_clean[target_variable].values

    apply_log = False
    if y.max() > 1000 or y.var() > 10000:
        apply_log = st.checkbox("AplicÄƒ transformare logaritmicÄƒ pentru variabila È›intÄƒ", value=True)
        if apply_log:
            y = np.log(y + 1)  # AdÄƒugÄƒm 1 pentru a evita log(0)
            st.info("Am aplicat logaritmul natural pentru variabila È›intÄƒ pentru a Ã®mbunÄƒtÄƒÈ›i performanÈ›a modelului.")

    numerical_columns = df_diabet_clean.select_dtypes(include=['float64', 'int64']).columns.tolist()

    if 'Diagnosis' in numerical_columns:
        numerical_columns.remove('Diagnosis')
    if target_variable in numerical_columns:
        numerical_columns.remove(target_variable)

    predictors_to_avoid = ['AntidiabeticMedications', 'Diagnosis']
    for col in predictors_to_avoid:
        if col in numerical_columns:
            numerical_columns.remove(col)

    X_columns = st.multiselect(
        "SelectaÈ›i caracteristicile pentru model:",
        numerical_columns,
        default=['BMI', 'Age', 'FastingBloodSugar', 'PhysicalActivity', 'DietQuality', 'SleepQuality']
    )

    if not X_columns:
        st.error("Trebuie sÄƒ selectaÈ›i cel puÈ›in o caracteristicÄƒ pentru model.")
        return df_diabet

    X = df_diabet_clean[X_columns]

    categorical_columns = X.select_dtypes(include=['object', 'category']).columns
    if not categorical_columns.empty:
        st.subheader("2. Codificarea variabilelor categorice")
        st.markdown("UrmÄƒtoarele variabile categorice vor fi codificate folosind one-hot encoding:")
        st.write(categorical_columns.tolist())

        X = pd.get_dummies(X)
        st.success(f"Codificare realizatÄƒ cu succes. Noul set de date are {X.shape[1]} caracteristici.")

    st.subheader("2. ÃmpÄƒrÈ›irea datelor Ã®n seturi de antrenare È™i testare")

    st.markdown("""
    UrmeazÄƒ sÄƒ Ã®mpÄƒrÈ›im setul de date Ã®n douÄƒ subseturi: unul pentru antrenarea modelului È™i altul pentru testare. 
    AceastÄƒ separare este esenÈ›ialÄƒ Ã®n procesul de Ã®nvÄƒÈ›are automatÄƒ, deoarece ne permite sÄƒ evaluÄƒm corect performanÈ›a modelului.

    Setul de antrenare permite modelului sÄƒ Ã®nveÈ›e relaÈ›iile dintre variabile È™i sÄƒ identifice tipare,
    Ã®n timp ce setul de testare ne ajutÄƒ sÄƒ verificÄƒm cÃ¢t de bine generalizeazÄƒ modelul pe date noi, nevÄƒzute Ã®n timpul antrenÄƒrii.
    Vom folosi 80% din date pentru antrenare È™i 20% pentru testare, un raport standard Ã®n domeniul Ã®nvÄƒÈ›Äƒrii automate.
    """)

    test_size = 0.2
    random_state = 42

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)

    st.markdown(f"- Date pentru antrenare: {X_train.shape[0]} Ã®nregistrÄƒri ({(1 - test_size) * 100:.0f}%)")
    st.markdown(f"- Date pentru testare: {X_test.shape[0]} Ã®nregistrÄƒri ({test_size * 100:.0f}%)")

    st.subheader("3. Antrenarea modelului de regresie liniarÄƒ")

    train_model = False
    if 'lr_model_diabet' not in st.session_state or st.button("AntreneazÄƒ modelul"):
        train_model = True

    if train_model:
        with st.spinner("Antrenez modelul de regresie liniarÄƒ..."):
            lr = linear_model.LinearRegression()
            model = lr.fit(X_train, y_train)



            st.session_state.lr_model_diabet = model
            st.session_state.X_train_diabet = X_train
            st.session_state.X_test_diabet = X_test
            st.session_state.y_train_diabet = y_train
            st.session_state.y_test_diabet = y_test
            st.session_state.target_variable_diabet = target_variable
            st.session_state.apply_log_diabet = apply_log

            y_train_pred = model.predict(X_train)



            st.write("X_train shape:", X_train.shape)
            st.write("X_test  shape:", X_test.shape)

            st.write("CoeficienÈ›i regresie liniarÄƒ:")
            st.write(pd.DataFrame({
                'CaracteristicÄƒ': X_train.columns,
                'Coeficient': model.coef_
            }).sort_values('Coeficient', ascending=False))

            st.write("Statistici HbA1c (train):", pd.Series(y_train).describe())
            st.write("Statistici HbA1c (test):", pd.Series(y_test).describe())

            st.write("Statistici HbA1c (train):", pd.Series(y_train).describe())
            st.write("Statistici HbA1c (test):", pd.Series(y_test).describe())

            st.subheader("4. Evaluarea modelului pe setul de antrenare")

            fig, ax = plt.subplots(figsize=(10, 6))
            ax.scatter(y_train_pred, y_train, alpha=0.5)
            ax.set_xlabel('Valori prezise')
            ax.set_ylabel('Valori reale')
            ax.set_title('ComparaÈ›ie Ã®ntre valorile reale È™i cele prezise (set de antrenare)')

            min_val = min(y_train.min(), y_train_pred.min())
            max_val = max(y_train.max(), y_train_pred.max())
            ax.plot([min_val, max_val], [min_val, max_val], 'r-')

            st.pyplot(fig)

            mse_train = mean_squared_error(y_train, y_train_pred)
            rmse_train = np.sqrt(mse_train)
            mae_train = mean_absolute_error(y_train, y_train_pred)
            r2_train = r2_score(y_train, y_train_pred)

            st.session_state.train_metrics_diabet = {
                'mse': mse_train,
                'rmse': rmse_train,
                'mae': mae_train,
                'r2': r2_train
            }

            st.markdown("**Metrici de performanÈ›Äƒ (set de antrenare):**")
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("MSE", f"{mse_train:.4f}")
            col2.metric("RMSE", f"{rmse_train:.4f}")
            col3.metric("MAE", f"{mae_train:.4f}")
            col4.metric("RÂ²", f"{r2_train:.4f}")

            y_test_pred = model.predict(X_test)

            st.subheader("5. Evaluarea modelului pe setul de testare")

            fig, ax = plt.subplots(figsize=(10, 6))
            ax.scatter(y_test_pred, y_test, alpha=0.5)
            ax.set_xlabel('Valori prezise')
            ax.set_ylabel('Valori reale')
            ax.set_title('ComparaÈ›ie Ã®ntre valorile reale È™i cele prezise (set de testare)')

            min_val = min(y_test.min(), y_test_pred.min())
            max_val = max(y_test.max(), y_test_pred.max())
            ax.plot([min_val, max_val], [min_val, max_val], 'r-')

            st.pyplot(fig)

            mse_test = mean_squared_error(y_test, y_test_pred)
            rmse_test = np.sqrt(mse_test)
            mae_test = mean_absolute_error(y_test, y_test_pred)
            r2_test = r2_score(y_test, y_test_pred)

            st.session_state.test_metrics_diabet = {
                'mse': mse_test,
                'rmse': rmse_test,
                'mae': mae_test,
                'r2': r2_test
            }

            st.markdown("**Metrici de performanÈ›Äƒ (set de testare):**")
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("MSE", f"{mse_test:.4f}")
            col2.metric("RMSE", f"{rmse_test:.4f}")
            col3.metric("MAE", f"{mae_test:.4f}")
            col4.metric("RÂ²", f"{r2_test:.4f}")

            with st.expander("Explicarea metricilor È™i interpretarea rezultatelor"):
                st.markdown("""
                ### Metrici de performanÈ›Äƒ:

                - **MSE (Mean Squared Error)**: Media pÄƒtratelor diferenÈ›elor dintre valorile reale È™i cele prezise.
                  - *Interpretare*: Valori mai mici indicÄƒ o potrivire mai bunÄƒ a modelului. MSE penalizeazÄƒ erorile mari mai sever decÃ¢t cele mici.
                  - *LimitÄƒ*: Nu are o scalÄƒ fixÄƒ, depinde de datele analizate.

                - **RMSE (Root Mean Squared Error)**: RÄƒdÄƒcina pÄƒtratÄƒ a MSE. Este Ã®n aceleaÈ™i unitÄƒÈ›i ca variabila È›intÄƒ.
                  - *Interpretare*: ReprezintÄƒ aproximativ "eroarea medie" Ã®n unitatea variabilei È›intÄƒ. Un RMSE de 0.5 pentru HbA1c Ã®nseamnÄƒ cÄƒ, Ã®n medie, predicÈ›iile sunt cu Â±0.5 puncte diferite de valorile reale.
                  - *CÃ¢nd este bun*: RMSE < 10% din intervalul valorilor variabilei È›intÄƒ este considerat bun.

                - **MAE (Mean Absolute Error)**: Media valorilor absolute ale erorilor.
                  - *Interpretare*: Similar cu RMSE, dar trateazÄƒ toate erorile Ã®n mod egal, indiferent de mÄƒrime.
                  - *ComparaÈ›ie cu RMSE*: DacÄƒ MAE este semnificativ mai mic decÃ¢t RMSE, Ã®nseamnÄƒ cÄƒ existÄƒ cÃ¢teva erori mari ("outliers" Ã®n predicÈ›ii).

                - **RÂ² (Coeficient de determinare)**: Procentul din variaÈ›ia variabilei È›intÄƒ explicat de model.
                  - *Interpretare*: 
                     - RÂ² = 1.0: Modelul explicÄƒ perfect variaÈ›ia (predicÈ›ie perfectÄƒ)
                     - RÂ² = 0.7: Modelul explicÄƒ 70% din variaÈ›ia datelor
                     - RÂ² = 0: Modelul nu este mai bun decÃ¢t media simplÄƒ a datelor
                     - RÂ² < 0: Modelul este mai rÄƒu decÃ¢t media simplÄƒ (extrem de slab)
                  - *Evaluare calitativÄƒ*:
                     - RÂ² > 0.9: Excelent
                     - RÂ² Ã®ntre 0.7-0.9: Bun
                     - RÂ² Ã®ntre 0.5-0.7: Moderat
                     - RÂ² Ã®ntre 0.3-0.5: Slab
                     - RÂ² < 0.3: Foarte slab

                ### Interpretarea diferenÈ›ei Ã®ntre setul de antrenare È™i testare:

                - **PerformanÈ›Äƒ similarÄƒ**: DacÄƒ metricile sunt apropiate pe ambele seturi, modelul generalizeazÄƒ bine.
                - **PerformanÈ›Äƒ mult mai bunÄƒ pe antrenare**: IndicÄƒ supraadjustare (overfitting) - modelul "memoreazÄƒ" datele de antrenare dar nu generalizeazÄƒ.
                - **PerformanÈ›Äƒ mult mai slabÄƒ pe testare**: Poate indica cÄƒ setul de testare conÈ›ine tipuri de date diferite faÈ›Äƒ de cel de antrenare.

                ### Interpretarea graficelor:

                - **Puncte aproape de linia roÈ™ie**: PredicÈ›ii bune
                - **Puncte rÄƒspÃ¢ndite aleatoriu**: Model slab
                - **Puncte formÃ¢nd un tipar (curba, grupuri)**: RelaÈ›ie nelinearÄƒ care nu e capturatÄƒ de model
                - **Puncte mai depÄƒrtate la capete**: Model care nu capteazÄƒ bine valorile extreme
                """)

            coefficients = pd.DataFrame({
                'CaracteristicÄƒ': X.columns,
                'Coeficient': model.coef_
            }).sort_values(by='Coeficient', ascending=False)

            coefficients['ImportanÈ›Äƒ (|Coeficient|)'] = np.abs(coefficients['Coeficient'])
            coefficients_abs = coefficients.sort_values(by='ImportanÈ›Äƒ (|Coeficient|)', ascending=False)

            st.session_state.coefficients_diabet = coefficients
            st.session_state.coefficients_abs_diabet = coefficients_abs

            st.subheader("6. ImportanÈ›a caracteristicilor")

            fig, ax = plt.subplots(figsize=(10, 8))
            sns.barplot(x='ImportanÈ›Äƒ (|Coeficient|)', y='CaracteristicÄƒ', data=coefficients_abs.head(15), ax=ax)
            ax.set_title('Top caracteristici dupÄƒ importanÈ›Äƒ absolutÄƒ')
            st.pyplot(fig)

            fig, ax = plt.subplots(figsize=(10, 8))
            top_pos_coeffs = coefficients.head(10)
            top_neg_coeffs = coefficients.tail(10)
            top_coeffs = pd.concat([top_pos_coeffs, top_neg_coeffs]).sort_values(by='Coeficient')
            sns.barplot(x='Coeficient', y='CaracteristicÄƒ', data=top_coeffs, ax=ax)
            ax.set_title('Top 10 coeficienÈ›i pozitivi È™i negativi')
            ax.axvline(x=0, color='gray', linestyle='--')
            st.pyplot(fig)

            st.markdown("**CoeficienÈ›ii modelului:**")
            st.dataframe(coefficients_abs)

            with st.expander("Interpretarea coeficienÈ›ilor"):
                st.markdown("""
                ### Cum sÄƒ interpretezi coeficienÈ›ii modelului:

                #### Magnitudinea coeficienÈ›ilor (importanÈ›a)
                - **CoeficienÈ›i cu valoare absolutÄƒ mare**: Caracteristicile cu valorile cele mai mari (pozitive sau negative) au cel mai mare impact asupra predicÈ›iei HbA1c.
                - **CoeficienÈ›i aproape de zero**: Aceste caracteristici au o influenÈ›Äƒ minimÄƒ Ã®n model.

                #### DirecÈ›ia coeficienÈ›ilor (semnul)
                - **CoeficienÈ›i pozitivi**: O creÈ™tere a acestei caracteristici conduce la o creÈ™tere a HbA1c. De exemplu, dacÄƒ "BMI" are un coeficient pozitiv, atunci cu cÃ¢t BMI-ul este mai mare, cu atÃ¢t HbA1c tinde sÄƒ fie mai ridicat (conform modelului).
                - **CoeficienÈ›i negativi**: O creÈ™tere a acestei caracteristici conduce la o scÄƒdere a HbA1c. De exemplu, dacÄƒ "PhysicalActivity" are un coeficient negativ, atunci cu cÃ¢t activitatea fizicÄƒ este mai intensÄƒ, cu atÃ¢t HbA1c tinde sÄƒ fie mai scÄƒzut.

                #### AtenÈ›ie la interpretare:
                1. **UnitÄƒÈ›i diferite**: CoeficienÈ›ii reflectÄƒ È™i unitÄƒÈ›ile de mÄƒsurÄƒ ale caracteristicilor. O caracteristicÄƒ mÄƒsuratÄƒ Ã®n mii va avea un coeficient mai mic decÃ¢t una mÄƒsuratÄƒ Ã®n unitÄƒÈ›i, chiar dacÄƒ importanÈ›a realÄƒ este similarÄƒ.
                2. **Colinearitate**: DacÄƒ existÄƒ caracteristici puternic corelate, interpretarea individualÄƒ a coeficienÈ›ilor poate fi Ã®nÈ™elÄƒtoare.
                3. **Variabile dummy**: Pentru variabilele categorice codificate (one-hot encoding), coeficienÈ›ii aratÄƒ diferenÈ›a faÈ›Äƒ de categoria de referinÈ›Äƒ.

                #### Exemplu de interpretare:
                DacÄƒ "FastingBloodSugar" are un coeficient de 0.5, Ã®nseamnÄƒ cÄƒ o creÈ™tere de 1 unitate (de exemplu, 1 mg/dL) Ã®n glicemia Ã  jeun este asociatÄƒ cu o creÈ™tere de 0.5 unitÄƒÈ›i Ã®n HbA1c (presupunÃ¢nd cÄƒ toate celelalte variabile rÄƒmÃ¢n constante).
                """)

                st.markdown("### Interpretarea specificÄƒ a celor mai influente caracteristici:")

                top_pos = coefficients.head(3)
                top_neg = coefficients.tail(3).iloc[::-1]

                st.markdown("#### Caracteristici cu influenÈ›Äƒ pozitivÄƒ:")
                for i, row in top_pos.iterrows():
                    st.markdown(
                        f"- **{row['CaracteristicÄƒ']}** (coeficient: {row['Coeficient']:.4f}): O creÈ™tere de 1 unitate Ã®n aceastÄƒ caracteristicÄƒ este asociatÄƒ cu o creÈ™tere de {row['Coeficient']:.4f} unitÄƒÈ›i Ã®n HbA1c, menÈ›inÃ¢nd toate celelalte variabile constante.")

                st.markdown("#### Caracteristici cu influenÈ›Äƒ negativÄƒ:")
                for i, row in top_neg.iterrows():
                    st.markdown(
                        f"- **{row['CaracteristicÄƒ']}** (coeficient: {row['Coeficient']:.4f}): O creÈ™tere de 1 unitate Ã®n aceastÄƒ caracteristicÄƒ este asociatÄƒ cu o scÄƒdere de {abs(row['Coeficient']):.4f} unitÄƒÈ›i Ã®n HbA1c, menÈ›inÃ¢nd toate celelalte variabile constante.")

    elif 'lr_model_diabet' in st.session_state:
        st.subheader("4. Evaluarea modelului pe setul de antrenare")

        st.markdown("**Metrici de performanÈ›Äƒ (set de antrenare):**")
        train_metrics = st.session_state.train_metrics_diabet
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("MSE", f"{train_metrics['mse']:.4f}")
        col2.metric("RMSE", f"{train_metrics['rmse']:.4f}")
        col3.metric("MAE", f"{train_metrics['mae']:.4f}")
        col4.metric("RÂ²", f"{train_metrics['r2']:.4f}")

        st.subheader("5. Evaluarea modelului pe setul de testare")

        st.markdown("**Metrici de performanÈ›Äƒ (set de testare):**")
        test_metrics = st.session_state.test_metrics_diabet
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("MSE", f"{test_metrics['mse']:.4f}")
        col2.metric("RMSE", f"{test_metrics['rmse']:.4f}")
        col3.metric("MAE", f"{test_metrics['mae']:.4f}")
        col4.metric("RÂ²", f"{test_metrics['r2']:.4f}")

        with st.expander("Explicarea metricilor È™i interpretarea rezultatelor"):
            st.markdown("""
            ### Metrici de performanÈ›Äƒ:

            - **MSE (Mean Squared Error)**: Media pÄƒtratelor diferenÈ›elor dintre valorile reale È™i cele prezise.
              - *Interpretare*: Valori mai mici indicÄƒ o potrivire mai bunÄƒ a modelului. MSE penalizeazÄƒ erorile mari mai sever decÃ¢t cele mici.
              - *LimitÄƒ*: Nu are o scalÄƒ fixÄƒ, depinde de datele analizate.

            - **RMSE (Root Mean Squared Error)**: RÄƒdÄƒcina pÄƒtratÄƒ a MSE. Este Ã®n aceleaÈ™i unitÄƒÈ›i ca variabila È›intÄƒ.
              - *Interpretare*: ReprezintÄƒ aproximativ "eroarea medie" Ã®n unitatea variabilei È›intÄƒ. Un RMSE de 0.5 pentru HbA1c Ã®nseamnÄƒ cÄƒ, Ã®n medie, predicÈ›iile sunt cu Â±0.5 puncte diferite de valorile reale.
              - *CÃ¢nd este bun*: RMSE < 10% din intervalul valorilor variabilei È›intÄƒ este considerat bun.

            - **MAE (Mean Absolute Error)**: Media valorilor absolute ale erorilor.
              - *Interpretare*: Similar cu RMSE, dar trateazÄƒ toate erorile Ã®n mod egal, indiferent de mÄƒrime.
              - *ComparaÈ›ie cu RMSE*: DacÄƒ MAE este semnificativ mai mic decÃ¢t RMSE, Ã®nseamnÄƒ cÄƒ existÄƒ cÃ¢teva erori mari ("outliers" Ã®n predicÈ›ii).

            - **RÂ² (Coeficient de determinare)**: Procentul din variaÈ›ia variabilei È›intÄƒ explicat de model.
              - *Interpretare*: 
                 - RÂ² = 1.0: Modelul explicÄƒ perfect variaÈ›ia (predicÈ›ie perfectÄƒ)
                 - RÂ² = 0.7: Modelul explicÄƒ 70% din variaÈ›ia datelor
                 - RÂ² = 0: Modelul nu este mai bun decÃ¢t media simplÄƒ a datelor
                 - RÂ² < 0: Modelul este mai rÄƒu decÃ¢t media simplÄƒ (extrem de slab)
              - *Evaluare calitativÄƒ*:
                 - RÂ² > 0.9: Excelent
                 - RÂ² Ã®ntre 0.7-0.9: Bun
                 - RÂ² Ã®ntre 0.5-0.7: Moderat
                 - RÂ² Ã®ntre 0.3-0.5: Slab
                 - RÂ² < 0.3: Foarte slab

            ### Interpretarea diferenÈ›ei Ã®ntre setul de antrenare È™i testare:

            - **PerformanÈ›Äƒ similarÄƒ**: DacÄƒ metricile sunt apropiate pe ambele seturi, modelul generalizeazÄƒ bine.
            - **PerformanÈ›Äƒ mult mai bunÄƒ pe antrenare**: IndicÄƒ supraadjustare (overfitting) - modelul "memoreazÄƒ" datele de antrenare dar nu generalizeazÄƒ.
            - **PerformanÈ›Äƒ mult mai slabÄƒ pe testare**: Poate indica cÄƒ setul de testare conÈ›ine tipuri de date diferite faÈ›Äƒ de cel de antrenare.

            ### Interpretarea graficelor:

            - **Puncte aproape de linia roÈ™ie**: PredicÈ›ii bune
            - **Puncte rÄƒspÃ¢ndite aleatoriu**: Model slab
            - **Puncte formÃ¢nd un tipar (curba, grupuri)**: RelaÈ›ie nelinearÄƒ care nu e capturatÄƒ de model
            - **Puncte mai depÄƒrtate la capete**: Model care nu capteazÄƒ bine valorile extreme
            """)

        st.subheader("6. ImportanÈ›a caracteristicilor")

        st.markdown("**CoeficienÈ›ii modelului:**")
        st.dataframe(st.session_state.coefficients_abs_diabet)

        fig, ax = plt.subplots(figsize=(10, 8))
        coefficients = st.session_state.coefficients_diabet
        top_pos_coeffs = coefficients.head(10)
        top_neg_coeffs = coefficients.tail(10)
        top_coeffs = pd.concat([top_pos_coeffs, top_neg_coeffs]).sort_values(by='Coeficient')
        sns.barplot(x='Coeficient', y='CaracteristicÄƒ', data=top_coeffs, ax=ax)
        ax.set_title('Top coeficienÈ›i pozitivi È™i negativi pentru predicÈ›ia HbA1c')
        ax.axvline(x=0, color='gray', linestyle='--')
        st.pyplot(fig)

    if 'lr_model_diabet' in st.session_state:
        st.subheader("7. PredicÈ›ie pentru un singur caz")

        st.markdown("""
        Acum cÄƒ modelul nostru este antrenat È™i evaluat, putem folosi acest model pentru a face predicÈ›ii
        individuale pentru nivelul HbA1c. SelectaÈ›i un index din setul de testare pentru a vedea
        cum modelul prezice nivelul HbA1c pentru acel caz specific È™i cÃ¢t de aproape este faÈ›Äƒ de valoarea realÄƒ.
        """)

        selected_index = st.selectbox("SelectaÈ›i un index:", st.session_state.X_test_diabet.index)

        if selected_index is not None:
            model = st.session_state.lr_model_diabet
            X_test = st.session_state.X_test_diabet
            y_test = st.session_state.y_test_diabet
            apply_log = st.session_state.apply_log_diabet

            single_prediction = model.predict(X_test.loc[selected_index].values.reshape(1, -1))[0]
            actual_value = y_test[X_test.index.get_loc(selected_index)]

            if apply_log:
                single_prediction_original = np.exp(single_prediction) - 1
                actual_value_original = np.exp(actual_value) - 1
                st.markdown(f"**Valoare prezisÄƒ (original):** {single_prediction_original:.4f}")
                st.markdown(f"**Valoare realÄƒ (original):** {actual_value_original:.4f}")
            else:
                st.markdown(f"**Valoare prezisÄƒ:** {single_prediction:.4f}")
                st.markdown(f"**Valoare realÄƒ:** {actual_value:.4f}")

            st.markdown("**Detaliile cazului:**")
            st.dataframe(X_test.loc[[selected_index]])

            st.markdown("#### AnalizÄƒ detaliatÄƒ a predicÈ›iei:")
            error = abs(single_prediction - actual_value)
            error_percent = (error / actual_value) * 100 if actual_value != 0 else float('inf')

            if apply_log:
                error_original = abs(single_prediction_original - actual_value_original)
                error_percent_original = (
                                                     error_original / actual_value_original) * 100 if actual_value_original != 0 else float(
                    'inf')
                col1, col2 = st.columns(2)
                col1.metric("Eroare absolutÄƒ", f"{error_original:.4f}")
                col2.metric("Eroare procentualÄƒ", f"{error_percent_original:.2f}%")
            else:
                col1, col2 = st.columns(2)
                col1.metric("Eroare absolutÄƒ", f"{error:.4f}")
                col2.metric("Eroare procentualÄƒ", f"{error_percent:.2f}%")

            if error_percent < 5:
                st.success("ğŸ¯ PredicÈ›ie excelentÄƒ! Eroarea este sub 5% din valoarea realÄƒ.")
            elif error_percent < 10:
                st.success("âœ… PredicÈ›ie bunÄƒ. Eroarea este Ã®ntre 5-10% din valoarea realÄƒ.")
            elif error_percent < 20:
                st.warning("âš ï¸ PredicÈ›ie acceptabilÄƒ. Eroarea este Ã®ntre 10-20% din valoarea realÄƒ.")
            else:
                st.error("âŒ PredicÈ›ie slabÄƒ. Eroarea depÄƒÈ™eÈ™te 20% din valoarea realÄƒ.")

    st.subheader("8. Interpretarea generalÄƒ a modelului È™i implicaÈ›ii medicale")
    with st.expander("Interpretarea generalÄƒ a rezultatelor"):
        st.markdown("""
        ### Cum sÄƒ interpretezi rezultatele modelului de regresie pentru HbA1c:

        #### 1. Calitatea generalÄƒ a modelului
        - **RÂ² Ã®ntre 0.7-1.0**: Modelul este bun sau excelent È™i explicÄƒ mare parte din variaÈ›ia datelor, ceea ce Ã®nseamnÄƒ cÄƒ factorii selectaÈ›i sunt puternic determinanÈ›i pentru nivelul HbA1c.
        - **RÂ² Ã®ntre 0.5-0.7**: Modelul este acceptabil, dar sugereazÄƒ cÄƒ existÄƒ È™i alÈ›i factori importanÈ›i care influenÈ›eazÄƒ HbA1c È™i nu sunt incluÈ™i Ã®n model.
        - **RÂ² sub 0.5**: Modelul este slab, indicÃ¢nd cÄƒ variabilele selectate explicÄƒ doar parÈ›ial variaÈ›ia HbA1c.

        #### 2. ImportanÈ›a factorilor pentru managementul diabetului

        **Factori cu coeficienÈ›i pozitivi semnificativi:**
        - AceÈ™ti factori sunt asociaÈ›i cu creÈ™terea HbA1c È™i pot reprezenta factori de risc pentru control glicemic deficitar
        - PacienÈ›ii ar trebui sfÄƒtuiÈ›i sÄƒ fie atenÈ›i la aceÈ™ti factori È™i sÄƒ-i gestioneze corespunzÄƒtor

        **Factori cu coeficienÈ›i negativi semnificativi:**
        - AceÈ™ti factori sunt asociaÈ›i cu scÄƒderea HbA1c È™i pot reprezenta factori protectori pentru un control glicemic bun
        - Sunt potenÈ›iale È›inte pentru intervenÈ›ii terapeutice È™i schimbÄƒri Ã®n stilul de viaÈ›Äƒ

        #### 3. AplicaÈ›ii clinice:

        - **Screening È™i prevenÈ›ie**: Identificarea persoanelor cu risc ridicat pe baza profilului factorilor
        - **Personalizarea intervenÈ›iilor**: Adaptarea recomandÄƒrilor È™i tratamentelor Ã®n funcÈ›ie de factorii cu cel mai mare impact
        - **Monitorizare**: UrmÄƒrirea factorilor cheie pentru a anticipa modificÄƒri ale HbA1c
        - **EducaÈ›ie**: Informarea pacienÈ›ilor despre factorii care le influenÈ›eazÄƒ nivelul HbA1c

        #### 4. LimitÄƒri ale modelului:

        - **RelaÈ›ii de cauzalitate**: Asocierea statisticÄƒ nu implicÄƒ neapÄƒrat cauzalitate
        - **Variabile neobservate**: Pot exista factori importanÈ›i care nu au fost incluÈ™i Ã®n model
        - **InteracÈ›iuni complexe**: Modelul liniar simplu nu capteazÄƒ interacÈ›iunile complexe dintre factori
        - **Variabilitate individualÄƒ**: RÄƒspunsul individual poate varia faÈ›Äƒ de tendinÈ›ele generale identificate de model
        """)

    if 'Diagnosis' in df_diabet_clean.columns:
        st.subheader("9. Compararea factorilor Ã®ntre pacienÈ›i cu È™i fÄƒrÄƒ diabet")

        diagnosis_col = 'Diagnosis'
        df_diabet_pozitiv = df_diabet_clean[df_diabet_clean[diagnosis_col] == 1]
        df_diabet_negativ = df_diabet_clean[df_diabet_clean[diagnosis_col] == 0]

        st.markdown("### ComparaÈ›ie statisticÄƒ pentru HbA1c:")

        col1, col2 = st.columns(2)
        with col1:
            st.markdown("#### PacienÈ›i fÄƒrÄƒ diabet:")
            st.write(df_diabet_negativ[target_variable].describe())

        with col2:
            st.markdown("#### PacienÈ›i cu diabet:")
            st.write(df_diabet_pozitiv[target_variable].describe())

        fig, ax = plt.subplots(figsize=(10, 6))
        sns.histplot(data=df_diabet_clean, x=target_variable, hue=diagnosis_col,
                     kde=True, palette=['green', 'red'], element='step')
        ax.set_title(f'DistribuÈ›ia {target_variable} Ã®n funcÈ›ie de diagnostic')
        ax.set_xlabel(target_variable)
        ax.set_ylabel('FrecvenÈ›Äƒ')
        ax.legend(['FÄƒrÄƒ diabet', 'Cu diabet'])
        st.pyplot(fig)

        if len(X_columns) > 0:
            st.markdown("### RelaÈ›ia dintre factorii selectaÈ›i È™i HbA1c Ã®n funcÈ›ie de diagnostic:")

            selected_factor = st.selectbox(
                "SelectaÈ›i un factor pentru analizÄƒ:",
                X_columns
            )

            fig, ax = plt.subplots(figsize=(10, 6))
            sns.scatterplot(data=df_diabet_clean, x=selected_factor, y=target_variable,
                            hue=diagnosis_col, palette=['green', 'red'], alpha=0.7)

            sns.regplot(data=df_diabet_negativ, x=selected_factor, y=target_variable,
                        scatter=False, ax=ax, color='green', line_kws={'linestyle': '--'})
            sns.regplot(data=df_diabet_pozitiv, x=selected_factor, y=target_variable,
                        scatter=False, ax=ax, color='red', line_kws={'linestyle': '--'})

            ax.set_title(f'RelaÈ›ia dintre {selected_factor} È™i {target_variable}')
            ax.legend(['FÄƒrÄƒ diabet', 'Cu diabet'])
            st.pyplot(fig)

            st.markdown("""
            **Interpretare:**

            Graficul de mai sus ilustreazÄƒ relaÈ›ia dintre factorul selectat È™i HbA1c, diferenÈ›iatÄƒ Ã®n funcÈ›ie de diagnostic.
            - Punctele verzi È™i linia verde reprezintÄƒ pacienÈ›ii fÄƒrÄƒ diabet
            - Punctele roÈ™ii È™i linia roÈ™ie reprezintÄƒ pacienÈ›ii cu diabet

            ObservaÈ›i:
            - DiferenÈ›ele Ã®n nivelul general al HbA1c Ã®ntre cele douÄƒ grupuri
            - DacÄƒ pantele liniilor de regresie sunt diferite, acest lucru sugereazÄƒ cÄƒ factorul influenÈ›eazÄƒ diferit HbA1c Ã®n cele douÄƒ grupuri
            - ÃmprÄƒÈ™tierea punctelor Ã®n jurul liniei de regresie indicÄƒ variabilitatea relaÈ›iei
            """)

    return df_diabet


def page_model_regresie_statsmodels(df_diabet):
    st.title("Model de regresie multiplÄƒ (OLS) cu statsmodels pentru HbA1c")

    st.markdown("""
    Vom folosi pachetul **statsmodels** pentru a construi un model de regresie liniarÄƒ multiplÄƒ (Ordinary Least Squares) 
    care sÄƒ explice variabila È›intÄƒ **HbA1c** pe baza altor variabile din setul nostru de date despre diabet.
    """)

    if not isinstance(df_diabet, pd.DataFrame):
        st.error("Nu existÄƒ date disponibile pentru analizÄƒ.")
        return

    # 1. CurÄƒÈ›are iniÈ›ialÄƒ È™i definirea È›intei
    cols_to_drop = ['PatientID', 'DoctorInCharge'] if 'PatientID' in df_diabet.columns else []
    df_clean = df_diabet.drop(cols_to_drop, axis=1) if cols_to_drop else df_diabet.copy()

    target_variable = "HbA1c"
    if target_variable not in df_clean.columns:
        st.error(f"Variabila È›intÄƒ '{target_variable}' nu existÄƒ Ã®n setul de date.")
        return

    if df_clean.shape[0] < 10:
        st.error("Nu existÄƒ suficiente date pentru a construi modelul de regresie.")
        return

    st.subheader("1. Definirea setului X (predictori) È™i y (È›intÄƒ)")

    y = df_clean[target_variable]
    numerical_cols = df_clean.select_dtypes(include=['float64', 'int64']).columns.tolist()
    # EliminÄƒm din coloanele numerice pe cele care nu vrem sÄƒ le folosim ca predictori:
    for col in ['Diagnosis', target_variable, 'AntidiabeticMedications']:
        if col in numerical_cols:
            numerical_cols.remove(col)

    if not numerical_cols:
        st.error("Nu existÄƒ coloane numerice disponibile pentru a fi folosite ca predictori.")
        return

    # 2. Selectarea predictorilor de cÄƒtre utilizator
    X_columns = st.multiselect(
        "SelectaÈ›i variabile numerice pentru regresie multiplÄƒ:",
        numerical_cols,
        default=numerical_cols[:5]  # primele 5 ca sugestie
    )

    if not X_columns:
        st.error("Trebuie sÄƒ selectaÈ›i cel puÈ›in o variabilÄƒ predictor.")
        return

    X = df_clean[X_columns]

    # 3. DacÄƒ existÄƒ categorice Ã®n X_columns (nu ar trebui, pentru cÄƒ am filtrat numeric), le putem codifica:
    cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()
    if cat_cols:
        st.subheader("Codificarea variabilelor categorice")
        st.markdown("Vom aplica one-hot encoding pentru coloanele categorice selectate:")
        st.write(cat_cols)
        X = pd.get_dummies(X, columns=cat_cols, drop_first=True)
        st.success(f"Au fost create {X.shape[1]} caracteristici Ã®n urma one-hot encoding.")

    # 4. ÃmpÄƒrÈ›irea Ã®n seturi de antrenare È™i testare
    st.subheader("2. ÃmpÄƒrÈ›irea datelor Ã®n antrenare È™i testare")
    test_size = st.slider("Procent test (% din total)", min_value=10, max_value=50, value=20, step=5)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size / 100, random_state=42
    )
    st.markdown(f"- {X_train.shape[0]} rÃ¢nduri pentru antrenare")
    st.markdown(f"- {X_test.shape[0]} rÃ¢nduri pentru testare")

    # 5. Construirea modelului OLS cu statsmodels
    st.subheader("3. Antrenarea modelului OLS (statsmodels)")
    if st.button("AntreneazÄƒ modelul OLS"):
        # AdÄƒugÄƒm constanta (intercept) manual
        X_train_const = sm.add_constant(X_train)
        X_test_const = sm.add_constant(X_test)

        model_ols = sm.OLS(y_train, X_train_const).fit()
        st.session_state.model_ols = model_ols
        st.session_state.X_test_const = X_test_const
        st.session_state.y_test = y_test

        # 5.1. AfiÈ™Äƒm sumarul complet
        st.text(model_ols.summary())

        # 5.2. Extragem È™i afiÈ™Äƒm coeficienÈ›ii Ã®ntr-un DataFrame
        coef_df = pd.DataFrame({
            'Coeficient': model_ols.params,
            'StdErr': model_ols.bse,
            't-val': model_ols.tvalues,
            'P>|t|': model_ols.pvalues,
            'IC 2.5%': model_ols.conf_int().iloc[:, 0],
            'IC 97.5%': model_ols.conf_int().iloc[:, 1]
        })
        coef_df.index.name = 'CaracteristicÄƒ'
        st.subheader("CoeficienÈ›i È™i statistici inferenÈ›iale")
        st.dataframe(coef_df)

        # 5.3. PredicÈ›ii È™i metrici pe setul de test
        y_pred_test = model_ols.predict(X_test_const)
        mse_test = mean_squared_error(y_test, y_pred_test)
        r2_test = r2_score(y_test, y_pred_test)

        st.subheader("4. PerformanÈ›a modelului pe setul de testare")
        st.write(f"- **MSE (test):** {mse_test:.4f}")
        st.write(f"- **RÂ² (test):** {r2_test:.4f}")

        # 5.4. Grafic real vs prezis (test)
        fig, ax = plt.subplots(figsize=(8, 6))
        ax.scatter(y_pred_test, y_test, alpha=0.5, color='orange')
        ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
        ax.set_xlabel("Valori prezise")
        ax.set_ylabel("Valori reale")
        ax.set_title("Real vs. Prezis (set test)")
        st.pyplot(fig)

        st.success("Model OLS antrenat È™i evaluat cu succes!")

    elif 'model_ols' in st.session_state:
        # DacÄƒ modelul a fost deja antrenat anterior, afiÈ™Äƒm din nou rezultatele
        model_ols = st.session_state.model_ols
        X_test_const = st.session_state.X_test_const
        y_test = st.session_state.y_test

        st.text(model_ols.summary())

        coef_df = pd.DataFrame({
            'Coeficient': model_ols.params,
            'StdErr': model_ols.bse,
            't-val': model_ols.tvalues,
            'P>|t|': model_ols.pvalues,
            'IC 2.5%': model_ols.conf_int().iloc[:, 0],
            'IC 97.5%': model_ols.conf_int().iloc[:, 1]
        })
        coef_df.index.name = 'CaracteristicÄƒ'
        st.dataframe(coef_df)

        y_pred_test = model_ols.predict(X_test_const)
        mse_test = mean_squared_error(y_test, y_pred_test)
        r2_test = r2_score(y_test, y_pred_test)

        st.write(f"- **MSE (test):** {mse_test:.4f}")
        st.write(f"- **RÂ² (test):** {r2_test:.4f}")

        fig, ax = plt.subplots(figsize=(8, 6))
        ax.scatter(y_pred_test, y_test, alpha=0.5, color='orange')
        ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
        ax.set_xlabel("Valori prezise")
        ax.set_ylabel("Valori reale")
        ax.set_title("Real vs. Prezis (set test)")
        st.pyplot(fig)
